{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "945ebf4a",
   "metadata": {},
   "source": [
    "# Как можно оценивать RAG\n",
    "\n",
    "## Есть разные варианты ошибок LLM:\n",
    "- Лингвистические (грамматика, синтаксис и т.д.) - решаются через улучшение данных на претрейне LLM\n",
    "- Этические (некорректное, предвзятое или оскорбительное поведение) - решаются через улучшение данных на претрейне LLM (***Alignment???***)\n",
    "- Фактологические (связанные с неверной или устаревшей информацией) - решаются через обновление обучающего корпуса данных(дорого), использование RAG\n",
    "\n",
    "## Как можно оценивать RAG:\n",
    "1. Оценка Retrieve части\n",
    "    1. **Retrieving метрики** - метрики ранжиронвания и классификации, которые оценивают выдачу контекста (MAP@k, NCDG@k и т.д.). **Но нужна разметка**.\n",
    "\n",
    "2. Оценка генерации\n",
    "    1. **Faithfulness (Answer~Context)** - Согласованность генеративного ответа к найденному контексту (можно считать в **онлайне** и **не нужна** разметка)\n",
    "    2. **Relevance (Answer~Query)** - Насколько сгенерированный ответ соответствует вопросу (можно считать в **онлайне** и **не нужна** разметка)\n",
    "    3. **Correctness(Answer~Answer\\*)** - Измеряет степень соответствия генеративного ответа эталонному ответу (расчет только в **офлайне** и **нужна** разметка)\n",
    "\n",
    "## Методы реализации расчета метрик:\n",
    "1. **Human Eval** - разметка ассесорами (дорого, долго, но качественно), нужен **Golden Set(валидационная выборка)**\n",
    "2. **LLM as a Judge** - разметка LLM (дешево, быстро, чаще хуже чем разметка ассесорами). Плохо следуют большому кол-ву инструкций [статья](https://openreview.net/pdf?id=R6q67CDBCH)\n",
    "3. **Детермминированные метрики** - precision, recall, F1, BLEU, ROUGE, BertScore, слабо отражают реальность\n",
    "\n",
    "## Фреймворки для оцеки RAG:\n",
    "- **RAGAS** \n",
    "\n",
    "## Дополнительно:\n",
    "- [Как оценивать современные RAG-системы?](https://youtu.be/fE3gDFi7tNQ?si=FbgW8avZEXK15vOI)\n",
    "- [Полное руководство по оценке компонентов системы RAG: что необходимо знать](https://habr.com/ru/articles/860390/)\n",
    "- [Руководство для начинающих по оценке конвейеров RAG с использованием RAGAS](https://llmarena.team/blog/rukovodstvo-dlya-nachinayushchih-po-ocenke-konvejerov-rag)\n",
    "- https://arxiv.org/pdf/2405.07437"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd360151",
   "metadata": {},
   "source": [
    "**Faithfulness (Answer~Context) Достоверность** - Согласованность генеративного ответа к найденному контексту (можно считать в **онлайне** и **не нужна** разметка) через LLM as a Judge. Необходимо сгенерить несколько ответов и отношение (кол-во ответов согласованных с контекстом) / (кол-во всех ответов), либо оценка согласованности.\n",
    "\n",
    "**Answer Relevancy** - Насколько сгенерированный ответ соответствует вопросу (можно считать в **онлайне** и **не нужна** разметка) генерируются 3 вопроса к полученному ответу и считается косинусное расстояние между вопросами и изначальным вопросом\n",
    "\n",
    "\n",
    "**Context Precision** - доля релевантных чанков контекста из всех извлеченных чанков\n",
    "**Context Recall** - доля извлечённых релевантных чанков от общего числа релевантных чанков\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fe933d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
